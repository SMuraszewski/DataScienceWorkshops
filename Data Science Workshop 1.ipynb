{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Real Data from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Semestral Project*: build a statistical model from predicting real estate prices based on property features from data placed on ad site(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curriculum\n",
    "\n",
    "## Getting the data\n",
    "### - Setting up the environement\n",
    "### - Anatomy of a Spider\n",
    "### - Anatomy of a Web Page\n",
    "### - Scrapy - a scraping framework\n",
    "### - Beautiful Soup\n",
    "### - Managing the Crawling Frontier\n",
    "### - Crawling Ethical Aspects \n",
    "## Processing the data\n",
    "### - Descriptive Analytics\n",
    "### - Feature Engineering\n",
    "### - Price Determining Factors\n",
    "## Price Prediction\n",
    "### - Training the model\n",
    "### - Model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Spider* - a program that:\n",
    "- visits web pages from a list called *the frontier*\n",
    "- parses them to extract information - data and links\n",
    "- manages the _crawling frontier_ (links to be visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selektory - z sieczki, jaką dostajemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://packtpub.com/packt/offers/free-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.scrapy.org/en/latest/topics/spiders.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You start by generating the initial Requests to crawl the first URLs, and specify a callback function to be called with the response downloaded from those requests.\n",
    "\n",
    "In the callback function, you parse the response (web page) and return either dicts with extracted data, Item objects, Request objects, or an iterable of these objects.\n",
    "\n",
    "In callback functions, you parse the page contents, typically using Selectors \n",
    "\n",
    "Finally, the items returned from the spider will be typically persisted to a database or written to a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class PythonEventsSpider(scrapy.Spider): #definiujemy nowego pająka\n",
    "    name = 'pythoneventsspider'\n",
    "\n",
    "    start_urls = ['https://www.python.org/events/python-events/',] #pod tym adresem strona z wydarzeniami Python\n",
    "    found_events = []\n",
    "    \n",
    "    #xpath - wchodzimy do struktury strony internetowej, szuka, gdzie znajdują się interesujące nas informacje\n",
    "    #xpath - określenie ścieżki w dokumencie, która nas interesuje\n",
    "    #twórca strony WWW musi ją zrobić w ramach standardów, żeby wyszukiwanie było skuteczne\n",
    "    \n",
    "    def parse(self, response):\n",
    "        for event in response.xpath('//ul[contains(@class, \"list-recent-events\")]/li'): #event - jeden wiersz, szukamy listy nieponumerowanej, gdzie jakiś dokument jest nazwany \"list recent events\" \n",
    "            event_details = dict() #tworzymy słownik\n",
    "            event_details['name'] = event.xpath('h3[@class=\"event-title\"]/a/text()').extract_first() #szukamy nazwy linku - <a>\n",
    "            event_details['location'] = event.xpath('p/span[@class=\"event-location\"]/text()').extract_first() #szukamy lokalizacji\n",
    "            event_details['time'] = event.xpath('p/time/text()').extract_first() #paragraf p - tutaj skolei czas\n",
    "            self.found_events.append(event_details)\n",
    "            \n",
    "    #jeden pająk do jednej strony        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed: Nie można odnaleźć określonej procedury.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1d1728e58e52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprocess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCrawlerProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m \u001b[1;34m'LOG_LEVEL'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'ERROR'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrawl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPythonEventsSpider\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mspider\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrawlers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspider\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scrapy\\crawler.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, settings, install_root_handler)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[0minstall_shutdown_handlers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_signal_shutdown\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mconfigure_logging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstall_root_handler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[0mlog_scrapy_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_signal_shutdown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scrapy\\utils\\log.py\u001b[0m in \u001b[0;36mlog_scrapy_info\u001b[1;34m(settings)\u001b[0m\n\u001b[0;32m    147\u001b[0m     logger.info(\"Versions: %(versions)s\",\n\u001b[0;32m    148\u001b[0m                 {'versions': \", \".join(\"%s %s\" % (name, version)\n\u001b[1;32m--> 149\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscrapy_components_versions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m                     if name != \"Scrapy\")})\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scrapy\\utils\\versions.py\u001b[0m in \u001b[0;36mscrapy_components_versions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;34m\"Twisted\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtwisted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;34m\"Python\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"- \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[1;34m\"pyOpenSSL\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_get_openssl_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;34m\"cryptography\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcryptography_version\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;34m\"Platform\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mplatform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scrapy\\utils\\versions.py\u001b[0m in \u001b[0;36m_get_openssl_version\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_get_openssl_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[1;32mimport\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mopenssl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLeay_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLEAY_VERSION\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\OpenSSL\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \"\"\"\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mOpenSSL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcrypto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSSL\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m from OpenSSL.version import (\n\u001b[0;32m     10\u001b[0m     \u001b[0m__author__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m__copyright__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m__email__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m__license__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m__summary__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m__title__\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\OpenSSL\\crypto.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcryptography\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m from OpenSSL._util import (\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mffi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\OpenSSL\\_util.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPY3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcryptography\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhazmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbindings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopenssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinding\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBinding\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\cryptography\\hazmat\\bindings\\openssl\\binding.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcryptography\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcryptography\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInternalError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcryptography\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhazmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbindings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_openssl\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mffi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcryptography\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhazmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbindings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopenssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conditional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCONDITIONAL_NAMES\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: Nie można odnaleźć określonej procedury."
     ]
    }
   ],
   "source": [
    "process = CrawlerProcess({ 'LOG_LEVEL': 'ERROR'})\n",
    "process.crawl(PythonEventsSpider)\n",
    "spider = next(iter(process.crawlers)).spider\n",
    "process.start()\n",
    "\n",
    "for event in spider.found_events: print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
